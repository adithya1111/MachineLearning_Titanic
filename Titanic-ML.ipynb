{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "train = pd.read_csv('titanic-train.csv')\n",
    "test = pd.read_csv('titanic-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# explore the dataset\n",
    "train.info()\n",
    "# age, cabin, emabrked has null values\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dropping unncessary columns\n",
    "train.drop(['PassengerId','Ticket','Name'],axis=1,inplace='True')\n",
    "test.drop(['PassengerId','Ticket','Name'],axis=1,inplace='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check missing rows or NaN values\n",
    "#print train.isnull().any()\n",
    "#print train['Embarked'].isnull().value_counts()\n",
    "# Value counts for embarked\n",
    "print train['Embarked'].value_counts()\n",
    "# number of nulls in each column of dataframe\n",
    "print train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data cleansing for embarked column\n",
    "# Fill NA's in embarked \n",
    "train['Embarked']=train['Embarked'].fillna('S')\n",
    "# Average values for Survived class for Embarked feature\n",
    "sns.factorplot('Embarked','Survived', data=train,size=4,aspect=3)\n",
    "# Plots\n",
    "fig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(15,5))\n",
    "\n",
    "# sns.factorplot('Embarked',data=titanic_df,kind='count',order=['S','C','Q'],ax=axis1)\n",
    "# sns.factorplot('Survived',hue=\"Embarked\",data=titanic_df,kind='count',order=[1,0],ax=axis2)\n",
    "sns.countplot(x='Embarked', data=train, ax=axis1)\n",
    "sns.countplot(x='Survived', hue=\"Embarked\", data=train, order=[1,0], ax=axis2)\n",
    "embark_perc = train[[\"Embarked\", \"Survived\"]].groupby(['Embarked'],as_index=False).mean()\n",
    "sns.barplot(x='Embarked', y='Survived', data=embark_perc,order=['S','C','Q'],ax=axis3)\n",
    "\n",
    "\n",
    "# create dummies for embarked and remove one of the columns from dummies - Train\n",
    "embark_dummies_titanic  = pd.get_dummies(train['Embarked'])\n",
    "embark_dummies_titanic.columns = ['Embarked_'+s for s in embark_dummies_titanic.columns]\n",
    "embark_dummies_titanic.drop(['Embarked_S'], axis=1, inplace=True)\n",
    "## create dummies for embarked and remove one of the columns from dummies - Test\n",
    "embark_dummies_test  = pd.get_dummies(test['Embarked'])\n",
    "embark_dummies_test.columns = ['Embarked_'+s  for s in embark_dummies_test.columns]\n",
    "embark_dummies_test.drop(['Embarked_S'], axis=1, inplace=True)\n",
    "\n",
    "train.drop(['Embarked'],inplace='True',axis=1)\n",
    "test.drop(['Embarked'],inplace='True',axis=1)\n",
    "# Join with base datasets\n",
    "#train = train.join(embark_dummies_titanic)\n",
    "#test  = test.join(embark_dummies_test)\n",
    "#train.drop(['Embarked'], axis=1,inplace=True)\n",
    "#test.drop(['Embarked'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data cleansing for fare column\n",
    "test['Fare'].fillna(test['Fare'].median(), inplace=True)\n",
    "train.Fare=train.Fare.astype(int)\n",
    "test.Fare=test.Fare.astype(int)\n",
    "\n",
    "fare_not_survived = train.Fare[train['Survived']==0]\n",
    "fare_survived=train.Fare[train['Survived']==1]\n",
    "\n",
    "avgerage_fare = pd.DataFrame([fare_not_survived.mean(), fare_survived.mean()])\n",
    "std_fare      = pd.DataFrame([fare_not_survived.std(), fare_survived.std()])\n",
    "print avgerage_fare\n",
    "print std_fare\n",
    "avgerage_fare.columns=std_fare.columns=['Survived']\n",
    "# plot\n",
    "train['Fare'].plot(kind='hist', figsize=(15,3),bins=100, xlim=(0,50))\n",
    "\n",
    "avgerage_fare.index.names = std_fare.index.names = [\"Survived\"]\n",
    "avgerage_fare.plot(yerr=std_fare,kind='bar',legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data cleansing for age column\n",
    "average_age_titanic   = train[\"Age\"].mean()\n",
    "std_age_titanic       = train[\"Age\"].std()\n",
    "count_nan_age_titanic = train[\"Age\"].isnull().sum()\n",
    "\n",
    "average_age_test   = test[\"Age\"].mean()\n",
    "std_age_test       = test[\"Age\"].std()\n",
    "count_nan_age_test = test[\"Age\"].isnull().sum()\n",
    "\n",
    "print train['Age'].count()\n",
    "print average_age_titanic,std_age_titanic,count_nan_age_titanic\n",
    "\n",
    "# generate random values between mean-sd and mean+sd for train and test\n",
    "rand_1 = np.random.randint(average_age_titanic - std_age_titanic, average_age_titanic + std_age_titanic, size = count_nan_age_titanic)\n",
    "rand_2 = np.random.randint(average_age_test - std_age_test, average_age_test + std_age_test, size = count_nan_age_test)\n",
    "\n",
    "\n",
    "# find nan values and replace with random values\n",
    "train[\"Age\"][np.isnan(train[\"Age\"])] = rand_1\n",
    "test[\"Age\"][np.isnan(test[\"Age\"])] = rand_2\n",
    "\n",
    "train['Age']=train['Age'].astype(int)\n",
    "test['Age']=test['Age'].astype(int)\n",
    "# replace nan;s with median\n",
    "#train['Age'].fillna(train['Age'].median(),inplace='True')\n",
    "#train['Age']=train['Age'].astype(int)\n",
    "#test['Age'].fillna(test['Age'].median(),inplace='True')\n",
    "#test['Age']=test['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cabin values\n",
    "print train.info()\n",
    "print train['Cabin'].count()\n",
    "print train['Cabin'].isnull().sum()\n",
    "# Since it has many null values, we can drop\n",
    "train.drop(['Cabin'],inplace='True',axis=1)\n",
    "test.drop(['Cabin'],inplace='True',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set value for family =1 instead of having sibsp and parch variables\n",
    "train['family']=np.where((train['SibSp']==1) | (train['Parch']==1),1,0)\n",
    "test['family']=np.where((test['SibSp']==1) | (test['Parch']==1),1,0)\n",
    "train.drop(['SibSp','Parch'],inplace='True',axis=1)\n",
    "test.drop(['SibSp','Parch'],inplace='True',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create new sex variable\n",
    "train['Sex_New'] = np.where((train.Age<=16),'Child',train.Sex)\n",
    "test['Sex_New'] = np.where((test.Age<=16),'Child',test.Sex)\n",
    "train.drop(['Sex'],inplace='True',axis=1)\n",
    "test.drop(['Sex'],inplace='True',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Classify sex column as Male, female and child for train and test\n",
    "sex_dummies_train = pd.get_dummies(train['Sex_New'])\n",
    "sex_dummies_train.columns=['Child','Female','Male']\n",
    "sex_dummies_train.drop(['Male'],inplace='True',axis=1)\n",
    "train.drop(['Sex_New'],inplace='True',axis=1)\n",
    "train=train.join(sex_dummies)\n",
    "\n",
    "sex_dummies_test = pd.get_dummies(test['Sex_New'])\n",
    "sex_dummies_test.columns=['Child','Female','Male']\n",
    "sex_dummies_test.drop(['Male'],inplace='True',axis=1)\n",
    "test.drop(['Sex_New'],inplace='True',axis=1)\n",
    "test=test.join(sex_dummies_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pclass variable\n",
    "pclass_dummies_titanic  = pd.get_dummies(train['Pclass'])\n",
    "pclass_dummies_titanic.columns = ['Class_1','Class_2','Class_3']\n",
    "pclass_dummies_titanic.drop(['Class_3'], axis=1, inplace=True)\n",
    "\n",
    "pclass_dummies_test  = pd.get_dummies(test['Pclass'])\n",
    "pclass_dummies_test.columns = ['Class_1','Class_2','Class_3']\n",
    "pclass_dummies_test.drop(['Class_3'], axis=1, inplace=True)\n",
    "\n",
    "train.drop(['Pclass'],axis=1,inplace=True)\n",
    "test.drop(['Pclass'],axis=1,inplace=True)\n",
    "\n",
    "train = train.join(pclass_dummies_titanic)\n",
    "test    = test.join(pclass_dummies_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define training and testing sets\n",
    "\n",
    "X_train = train.drop(\"Survived\",axis=1)\n",
    "Y_train = train[\"Survived\"]\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = logreg.predict(X_test)\n",
    "\n",
    "logreg.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Random Forests\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "random_forest.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "\n",
    "random_forest.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get Correlation Coefficient for each feature using Logistic Regression\n",
    "coeff_df = pd.DataFrame(train.columns.delete(0))\n",
    "print coeff_df\n",
    "coeff_df.columns = ['Features']\n",
    "coeff_df[\"Coefficient Estimate\"] = pd.Series(logreg.coef_[0])\n",
    "\n",
    "# preview\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
