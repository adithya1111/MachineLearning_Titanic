{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import headers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import re\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load titanic dataset\n",
    "train = pd.read_csv('titanic-train.csv')\n",
    "train.drop('Survived',1,inplace=True)\n",
    "test = pd.read_csv('titanic-test.csv')\n",
    "combined=train.append(test)\n",
    "combined.reset_index(inplace=True)\n",
    "combined.drop('index',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# checking the data\n",
    "combined.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature engineering on name field\n",
    "# Extract titles from name field\n",
    "combined['Title']=combined['Name'].apply(lambda xa:xa[xa.find(',')+1:xa.find('.')])\n",
    "print combined['Title'].value_counts()\n",
    "# Create mapping for titles\n",
    "# create  a dictionary of names\n",
    "name_title_dict = {\n",
    "                        \"Capt\":       \"Officer\",\n",
    "                        \"Col\":        \"Officer\",\n",
    "                        \"Major\":      \"Officer\",\n",
    "                        \"Jonkheer\":   \"Royalty\",\n",
    "                        'Don':        'Royalty',\n",
    "                        \"Sir\" :       \"Royalty\",\n",
    "                        \"Dr\":         \"Officer\",\n",
    "                        \"Rev\":        \"Officer\",\n",
    "                        \"the Countess\":\"Royalty\",\n",
    "                        \"Dona\":       \"Royalty\",\n",
    "                        \"Mme\":        \"Mrs\",\n",
    "                        \"Mlle\":       \"Miss\",\n",
    "                        \"Ms\":         \"Mrs\",\n",
    "                        \"Mr\" :        \"Mr\",\n",
    "                        \"Mrs\" :       \"Mrs\",\n",
    "                        \"Miss\" :      \"Miss\",\n",
    "                        \"Master\" :    \"Master\",\n",
    "                        \"Lady\" :      \"Royalty\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check age null values\n",
    "combined['Age'].isnull().sum()\n",
    "# replace null values with median based on sex and pclass\n",
    "# groupby age with sex,pclass,title\n",
    "median_age=combined.groupby(['Sex','Pclass','Title'])['Age'].median()\n",
    "# flatten multiindex series and assign to dataframe\n",
    "median_age_df=median_age.reset_index()\n",
    "print median_age_df\n",
    "# replace sex=female, pclass=3 and title=Ms which has Nan values for age with mean age for sex=female and pclass=3\n",
    "median_age_df['Age'].ix[13] = 24.5\n",
    "# for all null values of age , replace with corresponding median from sex,pclass,title\n",
    "# create combined_v01 dataframe to merge combined and median dataframe\n",
    "combined_v01 = pd.merge(combined,median_age_df,on=['Sex','Pclass','Title'],how='left')\n",
    "# new column to assign new age values which wont have any null values\n",
    "combined_v01['Newage']=combined_v01.apply(lambda x:x['Age_y'] if np.isnan(x['Age_x']) else x['Age_x'],axis=1)\n",
    "combined_v01.drop(['Age_x'],inplace=True,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop name from dataframe\n",
    "combined_v01.drop('Name',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace null values for fare with mean\n",
    "combined_v01['Fare'].fillna(combined.Fare.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace null values for embarked with mode\n",
    "combined_v01.Embarked.fillna(combined.Embarked.mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#replace null values with mode\n",
    "combined_v01.Cabin.fillna('U',inplace=True)\n",
    "# replace cabin with first letters\n",
    "combined_v01.Cabin=[s[0] for s in combined_v01.Cabin]\n",
    "combined_v01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create dummies function\n",
    "def get_dummies_func(df,column_name):\n",
    "    df1=pd.get_dummies(df[column_name])\n",
    "    df1.columns = [column_name+'_'+s for s in df1.columns]\n",
    "    df = pd.concat([df,df1],axis=1)\n",
    "    df.drop(column_name,axis=1,inplace=True)\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create dummies\n",
    "combined_v02=pd.DataFrame()\n",
    "a = ['Cabin','Title','Embarked']\n",
    "for s in a:\n",
    "    print s\n",
    "    combined_v01=get_dummies_func(combined_v01,s)\n",
    "combined_v01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code sex\n",
    "combined_v01.Sex=combined_v01.Sex.map({'male':0,'female':1})\n",
    "combined_v01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create family size\n",
    "combined_v01['Familysize'] = combined_v01.SibSp + combined_v01.Parch\n",
    "combined_v01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define family status function\n",
    "def family_size_func(s):    \n",
    "    if s==1:\n",
    "        return 'singleton'\n",
    "    elif s>=2 & s<=4:\n",
    "        return 'smallfamily'\n",
    "    elif s>=5:\n",
    "        return 'largefamily'   \n",
    "combined_v01['family_status'] = [family_size_func(s) for s in combined_v01.Familysize]\n",
    "combined_v01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get dummies for family status\n",
    "combined_v01 = get_dummies_func(combined_v01,'family_status')\n",
    "combined_v01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get dummies for pclass\n",
    "pclass_dummies = pd.get_dummies(combined_v01['Pclass'])\n",
    "pclass_dummies.columns = ['Pclass_'+str(s) for s in pclass_dummies.columns]\n",
    "print pclass_dummies.head(5)\n",
    "combined=pd.concat([combined_v01,pclass_dummies],axis=1)\n",
    "#combined.head(50)\n",
    "combined_v01.drop('Pclass',axis=1,inplace=True)\n",
    "combined_v01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop ticket column\n",
    "combined_v01.drop('Ticket',axis=1,inplace=True)\n",
    "combined_v01.drop('PassengerId',axis=1,inplace=True)\n",
    "combined_v01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_v01.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "features = ['Newage','Fare']\n",
    "normalized_X = preprocessing.normalize(combined_v01[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_v02 = combined_v01.copy()\n",
    "combined_v02.drop(['Age_y'],axis=1,inplace=True)\n",
    "combined_v02[features] = normalized_X\n",
    "combined_v02.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scaling & normalization\n",
    "'''combined.info()\n",
    "combined_v02 = combined_v01.copy()\n",
    "combined_v02.drop(['Age_y'],axis=1,inplace=True)\n",
    "combined_v02.info()\n",
    "features = ['Newage','Fare']\n",
    "combined_v02[features] = combined_v02[features].apply(lambda x: x/x.max(), axis=0)\n",
    "combined_v02.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The data is stored in such a way that train data has survived class and test data doesnt have it. We have combined them into a\n",
    "# single dataframe. Now seperate them to train and test\n",
    "train = pd.read_csv('titanic-train.csv')\n",
    "train_x = combined_v02.ix[0:890]\n",
    "train_y=train.Survived\n",
    "test_x=combined_v02.ix[891:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.828282828283\n",
      "Best parameters: {'n_estimators': 210, 'criterion': 'entropy', 'max_depth': 7}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(max_features='sqrt')\n",
    "\n",
    "parameter_grid = {\n",
    "                 'max_depth' : [4,5,6,7,8],\n",
    "                 'n_estimators': [200,210,240,250],\n",
    "                 'criterion': ['gini','entropy']\n",
    "                 }\n",
    "\n",
    "cross_validation = StratifiedKFold(train_y, n_folds=5)\n",
    "\n",
    "grid_search = GridSearchCV(forest,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=cross_validation)\n",
    "\n",
    "grid_search.fit(train_x, train_y)\n",
    "\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# References : http://ahmedbesbes.com/how-to-score-08134-in-titanic-kaggle-challenge.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
